## BERT 中文实体提取

### 核心功能

- 加载 MSRA 中文 NER 标注数据集，完成数据清洗与格式转换；

- 基于 `transformers` 库封装的 BERT 模型，实现 Token 级别的分类训练；

- 解决了 BERT 分词后子词与原始汉字标签不匹配的问题（标签对齐）；

- 模型训练完成后自动保存，支持后续直接加载与预测；

- 提供评估指标（准确率、F1 分数）与实体提取可视化输出；

- 支持批量测试句子，自动提取并打印实体内容与实体类型。

### 模型效果

#### 评估结果

在验证集上的效果如下：

```
{
	'eval_loss': 0.05742316320538521, 
	'eval_model_preparation_time': 0.001, 
	'eval_accuracy': 0.9870285372181201, 
	'eval_O_f1': 0.9955897319914057, 
	'eval_B-ORG_f1': 0.851063829787234, 
	'eval_I-ORG_f1': 0.9043927648578811, 
	'eval_B-PER_f1': 0.9887640449438202, 
	'eval_I-PER_f1': 0.989010989010989, 
	'eval_B-LOC_f1': 0.9340659340659341, 
	'eval_I-LOC_f1': 0.8979591836734694, 
	'eval_runtime': 1.1561, 
	'eval_samples_per_second': 86.495, 
	'eval_steps_per_second': 11.244
}
```

- 损失值为 0.057，接近 0，说明模型在验证集上的预测结果和真实标签偏差极小，拟合效果不错；
- 整体准确率为 0.987，说明模型在绝大多数情况下都能够正确判断每个汉字的情况；
- 每种标签的 F1 分数基本都在 0.90 以上，有些甚至达到了 0.989，这种指标兼顾精确率与召回率，能够非常全面评估识别结果。

#### 测试结果

测试了若干句子，涵盖了不同场景，效果如下：

```
句子: 今天我约了王浩在恭王府吃饭，晚上在天安门逛逛。
 PER: 王浩
 LOC: 恭王府
 LOC: 天安门
 
句子: 人工智能是未来的希望，也是中国和美国的冲突点。
 LOC: 中国
 LOC: 美国
 
句子: 明天我们一起在海淀吃个饭吧，把叫刘涛和王华也叫上。
 LOC: 海淀
 PER: 刘涛
 PER: 王华
 
句子: 同煤集团同生安平煤业公司发生井下安全事故 19名矿工遇难
 ORG: 同煤集团
 ORG: 同生安平煤业公司
 
句子: 山东省政府办公厅就平邑县玉荣商贸有限公司石膏矿坍塌事故发出通报
 ORG: 山东省政府办公厅
 ORG: 平邑县玉荣商贸有限公司
 
句子: [新闻直播间]黑龙江:龙煤集团一煤矿发生火灾事故
 LOC: 黑龙江
 ORG: 龙煤集团
 
句子: 妈妈让我给舅舅王明送一箱水果到南京市建邺区的万达广场
 PER: 王明
 LOC: 南京市
 LOC: 建邺区
 LOC: 万达广场
 
句子: 招商银行股份有限公司上海浦东分行与阿里巴巴集团达成金融科技合作
 ORG: 招商银行股份有限公司
 ORG: 上海浦东分行
 ORG: 阿里巴巴集团
 
句子: 导演张艺谋的新电影将在西安市曲江新区的大唐不夜城举办首映礼，主演是周冬雨和易烊千玺
 PER: 张艺谋
 LOC: 西安市
 LOC: 曲江新区
 LOC: 大唐不夜城
 PER: 周冬雨
 PER: 易烊千玺

句子: 我叫李北京，老家在河北省北京市县，和朋友张上海一起在美团科技上班
 PER: 李北京
 LOC: 河北省
 LOC: 北京市县
 PER: 张上海
 ORG: 美团科技
```

可以看出，基本都能够正确的提取出实体，将人名、地名、机构名识别准确无误。

